{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cbbd65-0367-4693-82cc-750f5f88fe67",
   "metadata": {},
   "source": [
    "# Отчёт 27.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7782afb-c034-4ee1-a7ca-87a8827171f0",
   "metadata": {},
   "source": [
    "## ТЗ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ffdfc3-5340-4132-86ff-b1aa4971f1cd",
   "metadata": {},
   "source": [
    "В проекте работаю над моделированием системы хранения данных. В качестве целевого значения рассматривается производительность системы, целевое значение зависит от признаков: \n",
    "\n",
    "**непрерывные:**\n",
    "\n",
    "`nodes` - количество узлов: $4,\\,5,\\,\\cdots,100$;\n",
    "\n",
    "`size` - размер объекта: $4,\\,5,\\;\\cdots\\,128e3$ (KB); \n",
    "\n",
    "**категориальные:**\n",
    "\n",
    "`type` - тип действия: запись / чтение; \n",
    "\n",
    "`protection` - защита: REP 2, REP 3, EC2.1;\n",
    "\n",
    "`Hardware Chassis`: X205 / VEGMAN; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df4dc1-ee3d-45d9-8615-8ac12803f3b1",
   "metadata": {},
   "source": [
    "Мы получаем данные со стенда с шестнадцатью узлами (имеем замеры для nodes $= 4, \\cdots\\,16$ ) для различных комбинаций оставшихся признаков. Таким образом, математически, **замер** можно определить следующим образом $$(\\,\\boldsymbol{v}_{i_0,i_1,i_2,i_3,i_4}\\;|\\;nodes(i_0),\\,size(i_1),\\,type(i_2),\\,protection(i_3),\\,HW\\_chassis(i_4)\\,),\\;\\boldsymbol{v}_{i_0,i_1,i_2,i_3,i_4}\\in R$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50011d5-835a-4133-832b-80ae874f84b0",
   "metadata": {},
   "source": [
    "На имеющихся данных необходимо обучить модель $M(nodes, size, type, protection, HW\\_chassis)$, в первую очередь нас интересует экстраполяционная способность этой модели по параметру $nodes$: в данных $nodes \\in [4,16]$, хотим знать поведение целевого значения для $nodes \\in [4, 100]$ и всевозможных комбинаций остальных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b466804-c60d-4fc2-bbfb-9e9a95bdd646",
   "metadata": {},
   "source": [
    "## РЕАЛИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2115e29d-5296-4e7f-ae3b-c63e91b7c45e",
   "metadata": {},
   "source": [
    "**Чтение замеров**\n",
    "\n",
    "Данные (замеры) поступают в виде .txt / .md файлов, в зависимости от политики защиты (признак protection) вид записи в файл может отличаться. \n",
    "\n",
    "Для чтения данных написан скрипт `READER`, читающий все файлы папки sizes и записывающий необходимые данные в словарь `Data`, в котором ключи --- параметры замера. `Data` имеет следующую структуру: $$\\left\\{\\begin{pmatrix}protection \\\\ size \\\\ nodes \\\\ w/r \\\\ HW\\_chassis \\end{pmatrix}:\\;\\begin{Bmatrix}MB/s: & list \\\\ avg: & list\\\\ min: & list \\\\ med: & list \\\\ max: & list \\\\ p(90): & list \\\\ p(95): & list \\\\ op/s: & list \\\\ op/s\\_loss: & list \\\\ SUM\\_MB/s: & float \\\\ SUM\\_op/s: & float\\end{Bmatrix}\\right\\}$$\n",
    "\n",
    "*принцип работы:*\n",
    "\n",
    "С помощью `glob.glob` собираем все .txt и .md файлы из папки, конкатенируем их.\n",
    "\n",
    "Проходимся по файлам циклом\n",
    "\n",
    "Обрабатываем файл так: создаём list, добавляем туда все строки из файла и с while проходимся по строчкам: мы знаем, что каждый замер начинается с '###' и имеет фиксированный тип, по ходу записываем признаки в ключ временного словаря `Params`, а целевое значение и побочную информацию (min, max, avg, et c.) во временный словарь `Input`. Так, после обработки замера нам нужно лишь присвоить `Data[tuple(Params.values())] = Input`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb683b91-1445-4225-879e-ff8dbf383fc2",
   "metadata": {},
   "source": [
    "**Выгрузка данных**\n",
    "\n",
    "В ходе работы мне была поставлена задача конвертировать исходные .txt / .md данные в .xlsx документ.\n",
    "\n",
    "Скрипты `CONVERTER` и `WRITER` конвертируют словарь `Data` в список и выгружает его в виде .xlsx файла\n",
    "\n",
    "*принцип работы:*\n",
    "\n",
    "`CONVERTER` циклом переписывает значения из словаря в новый список.\n",
    "\n",
    "`WRITER` переводит list `Data` полученный в результате работы конвертера в `pd.DataFrame` и методом `.to_excel` выгружает .xlsx док."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c6f82-52e7-4ce9-b116-c46e82ac9726",
   "metadata": {},
   "source": [
    "**Отрисовка данных**\n",
    "\n",
    "Как для сырых данных так и для предсказанных выводятся графики - скрипты `GRAPHS (RAW DATA)`, `GRAPHS (PREDICTED DATA)`. Переменная `parametr` определяет, какой признак будет по оси абсцисс - он принимает значения `size`, `nodes`. Словарь `fix_params` - фиксирует оставшиеся признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4b60d-9ffc-41d6-853a-d84441c5d434",
   "metadata": {},
   "source": [
    "**Препроцессинг данных**\n",
    "\n",
    "Перед обучением модели необходимо предобработать данные:\n",
    "\n",
    "Для категориальных признаков выбран метод `One Hot Encoder`.\n",
    "\n",
    "**One Hot Encoder**\n",
    "\n",
    "Для реализации написана функция `features_transformation(Data: dict) -> pd.DataFrame:`. Encoding реализован pd методом `.get_dummies`, в связи с этим есть некоторые проблемы с требованием ко входным данным. Поскольку мы планируем использовать кодированные данные для обучения, то их размерность должна быть *чётко фиксирована*: при использовании `M.predict()` мы должны иметь возможность посмотреть на предсказанные значения на любом наборе параметров. `.get_dummies` создаёт лишь те столбцы значений cat. признаков, которые есть в `Data`, иначе говоря, если мы выберем подсловарь в `Data`, то, возможно, количество столбцов при действии на этот подсловарь функцией `features_transformation` будет меньше чем при действии на исходный словарь и это большая проблема, ведь признаки мы хотим фиксировать, чтобы посмотреть на предсказание, и, поэтому, кол - во столбцов будет строго меньше.\n",
    " \n",
    "Чтобы решить эту проблему написан скрипт `DOCUMENTATION` он фиксирует в словаре `doc` какие бывают значения параметров и добавляет в `Data` записи, перебирающие всевозможные комбинации признаков. Функция `features_transformation` обрабатывает это и выдаёт лишь DataFrame, соответствующий входному словарю. Это решает проблему зависимости размерности признаков при действии функции от входного словаря.\n",
    "\n",
    "**Преобразование непрерывных признаков**\n",
    "\n",
    "Знаем, что $\\text{target value}\\;|\\;\\text{nodes}\\sim \\log (\\text{nodes})$\n",
    "\n",
    "\n",
    "Введём для `numerical` параметров - `nodes, size` - базисные функции:\n",
    "\n",
    "$$\\boldsymbol{\\phi}_{size}(s) = \\begin{pmatrix}\n",
    "e^{-(s - 8)^2 / 2e4}\\\\\n",
    "e^{-(s - 128)^2 / 2e4}\\\\\n",
    "e^{-(s - 1e3)^2 / 2e4}\\\\\n",
    "e^{-(s - 128e3)^2 / 2e4}\\\\\n",
    "1\\\\\n",
    "s\\\\\n",
    "e^{-s}\\\\\n",
    "e^{-s^2}\n",
    "\\end{pmatrix}\\in R^{8};\\;\\boldsymbol{\\phi}_{nodes}(n) = \\begin{pmatrix}\n",
    "\\log(n)\\\\\n",
    "1\\\\\n",
    "n\n",
    "\\end{pmatrix}\\in R^3$$\n",
    "\n",
    "$$\\boldsymbol{\\phi}(n,\\,s) = (\\;\\boldsymbol{\\phi}_{nodes}(n)_i\\cdot \\boldsymbol{\\phi}_{size}(s)_j\\;)_{(i,j)}\\in R^{24}$$\n",
    "\n",
    "Для `categorial` параметров - `protection, type, HW_chassis` - One Hot Encoder\n",
    "\n",
    "\n",
    "Таким образом, модель приняла вид:\n",
    "\n",
    "$$\\hat{v}\\,(i_0\\,i_1\\,\\cdots\\,i_4) = \\boldsymbol{w}^\\top \\begin{pmatrix}\n",
    "\\boldsymbol{\\phi}(nodes\\,(i_0),\\,size\\,(i_1))\\\\\n",
    "\\boldsymbol{\\text{OHE}}(protection\\,(i_2),\\;type\\,(i_3),\\;HW\\_chassis\\,(i_4))\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "где $\\boldsymbol{\\text{OHE}}$ - кодирование наших `cat.` параметров.\n",
    "\n",
    "Далее - скейлим непрерывные признаки `sklearn.preprocessing.StandartScaler`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960630c1-68f0-45fe-b009-5ee021e5c4f7",
   "metadata": {},
   "source": [
    "**Обучение модели**\n",
    "\n",
    "Модель - `sklearn.linear_model.LinearRegression`\n",
    "\n",
    "Предобрабатываем данные, бутстрапим, на обучающей учим модель. Выводим матрицу весов.\n",
    "\n",
    "*В дальнейшем планируется перед бутстрапингом разделить дату на тестовую и обучающую (пока данных мало - смысла в этом нет).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf6b644-8d7d-48da-af71-bf323d077810",
   "metadata": {},
   "source": [
    "**Оценка качества модели**\n",
    "\n",
    "Модель оценивается метриками Mean Squared Error (MSE) и $R^2_{adj}$. Примем соглашение по интерперетации $R^2_{adj}$: \n",
    "\n",
    "$R^2_{adj} < 0.5$ - неудовлетворительно; $0.8 \\geq R^2_{adj}> 0.5$ - удовлетворительно; $R^2_{adj} > 0.8$ - хорошо.\n",
    "\n",
    "Использованы методы `.r2_score` и `mean_squared_error` библиотеки `sklearn.metrics` из $R^2$ выражается $R^2_{adj}$: $$R^2_{adj} = 1- (1 - R^2)\\frac{n-1}{n-k-1}$$ $n$ - кол - во данных, $k$ - кол - во параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412bfc91-0f00-4f2b-bb92-2faf6b811dde",
   "metadata": {},
   "source": [
    "**Результат**\n",
    "\n",
    "Обученная модель показывает хорошие результаты по метрике $R^2_{adj}$: от $.81$ до $.815$. Для сравнения - `RandomForest` даёт показатель $\\sim .9$ (поскольку экстраполяционная способность случайного леса околонулевая - мы его не используем)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
